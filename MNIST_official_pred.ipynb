{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "因为我们保存的是参数，然后用的又是 ipynb，这里网络架构只好重新再写一下"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import mnist\n",
    "from torchvision import transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "CNN(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (out): Linear(in_features=84, out_features=1, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5,padding=2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.pool=nn.AvgPool2d(2,2)\n",
    "        self.fc1=nn.Linear(400,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.out=nn.Linear(84,1)\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.out(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size=x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n",
    "cnn=CNN()\n",
    "cnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict=torch.load('saves/official_cnn_params.pth')\n",
    "cnn.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "也得换一下保存的内存设备为gpu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0')\n",
    "cnn=cnn.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "评估的时候，我一边挂着游戏，一边跑\n",
    "结果提示 DataLoader worker(pid xxx) exited unexpectedly\n",
    "线程数不够了哈哈，索性这里直接就不要 worker 了\n",
    "主要还是训练费时间，从磁盘\\cache取数也就那样吧"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "trans=transforms.Compose([transforms.ToTensor(),\n",
    "                          transforms.Normalize([0.5],[0.5])]\n",
    ")\n",
    "train_set=mnist.MNIST('official_data',train=True,transform=trans)\n",
    "test_set=mnist.MNIST('official_data',train=False,transform=trans)\n",
    "train_loader=DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_set,batch_size=64,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5.0036]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=train_loader.dataset[0][0]\n",
    "x=x.view(-1,x.size()[0],x.size()[1],x.size()[2])\n",
    "x=x.to(device)\n",
    "y_pred=cnn(x)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5]], device='cuda:0')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=y_pred.long() # 其实不建议这样写，tensor有long()却没有float32()就离谱，不统一\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，OK的，没问题\n",
    "接下来我们做一下评估\n",
    "这里我们使用 torchmetrics\n",
    "可以用 torchmetrics.functional.accuracy(preds,target)\n",
    "也可以用 torchmetrics.Accuracy() 对象\n",
    "这个对象你可以一批一批预测 batch，返回当前batch的acc，同时它内部还会累加样本数和正确数\n",
    "对 batch 预测的同时，最后你可以 .compute() 得到整个样本的预测准确率\n",
    "当你不需要累加时，只需 .reset() 即可\n",
    "主要 train_loader 第一维是样本数，第二维是 (X,y) 的一个 tuple，不好直接取出整个特征集和标签集\n",
    "如果这俩维度颠倒过来就方便了，可惜它不是这样\n",
    "所以我会选用 Accuracy() 对象"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(0.2638, device='cuda:0'), tensor(0.2633, device='cuda:0'))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "train_accuracy=torchmetrics.Accuracy().to(device) # 似乎只要是对象就得挪一下，这还真是麻烦\n",
    "test_accuracy=torchmetrics.Accuracy().to(device)\n",
    "for X_train,y_train in iter(train_loader):\n",
    "    X_train=X_train.to(device)\n",
    "    y_train=y_train.to(device)\n",
    "    y_train=y_train.reshape(y_train.size()[0],1)\n",
    "    y_pred=cnn(X_train).to(torch.int)\n",
    "    train_accuracy(y_pred,y_train)\n",
    "for X_test,y_test in iter(test_loader):\n",
    "    X_test=X_test.to(device)\n",
    "    y_test=y_test.to(device)\n",
    "    y_test=y_test.reshape(y_test.size()[0],1)\n",
    "    y_pred=cnn(X_test).to(torch.int)\n",
    "    test_accuracy(y_pred,y_test)\n",
    "train_acc=train_accuracy.compute()\n",
    "train_accuracy.reset()\n",
    "test_acc=test_accuracy.compute()\n",
    "test_accuracy.reset()\n",
    "train_acc,test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这个准确率着实真不咋地\n",
    "主要一方面模型没怎么优化吧\n",
    "另一方面训练的代数还是不够\n",
    "网上的话优化版差不多100次才行，500次就很不错了\n",
    "均方差5到10+，开根看的话基本就是一个差2，这误差确实太大了，就好比 4 平均可能预测到 2 到 6 这样"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "那么接下来，直接做一下 kaggle 的 MNIST，练一下 torch 对 csv 怎么使用的\n",
    "顺便也优化一下咱们的cnn网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}